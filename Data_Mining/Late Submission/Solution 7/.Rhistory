install.packages("caret")
library(caret)
library(rpart.plot)
data = read.csv("E:\\2ndMSIT\\Intro_to_ML\\DataScience_2019501037\\Data_Mining\\Late Submission\\Solution 3\\lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(data)
summary(data)
x = data[,1:4]
y = as.factor(data$Label)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
plot(model)
text(model)
rpart.plot(model)
#Information Gain
sum(y==predict(model,x,type="class"))/length(y)
#miscalassification error
1-sum(y==predict(model,x,type="class"))/length(y)
model1 = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
plot(model1)
text(model1)
rpart.plot(model1)
#Information Gain
sum(y==predict(model1,x,type="class"))/length(y)
#miscalassification error
1-sum(y==predict(model1,x,type="class"))/length(y)
data = read.csv("E:\\2ndMSIT\\Intro_to_ML\\DataScience_2019501037\\Data_Mining\\Late Submission\\Solution 3\\lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(data)
summary(data)
x = data[,1:4]
y = as.factor(data$Label)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
library(rpart.plot)
install.packages("rpart.plot")
install.packages("caret")
data = read.csv("E:\\2ndMSIT\\Intro_to_ML\\DataScience_2019501037\\Data_Mining\\Late Submission\\Solution 3\\lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(data)
summary(data)
x = data[,1:4]
y = as.factor(data$Label)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
install.packages("rpart")
data = read.csv("E:\\2ndMSIT\\Intro_to_ML\\DataScience_2019501037\\Data_Mining\\Late Submission\\Solution 3\\lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(data)
summary(data)
x = data[,1:4]
y = as.factor(data$Label)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
install.packages(c("arules", "arulesViz", "backports", "BH", "brio", "callr", "caTools", "cli", "colorspace", "cpp11", "crayon", "crosstalk", "data.table", "desc", "diffobj", "dplyr", "DT", "fansi", "farver", "fastmap", "ggplot2", "gplots", "hexbin", "htmltools", "htmlwidgets", "httpuv", "isoband", "jsonlite", "lifecycle", "magrittr", "mime", "pillar", "pkgbuild", "pkgload", "plotly", "processx", "promises", "ps", "Rcpp", "rlang", "rprojroot", "rstudioapi", "shiny", "shinythemes", "testthat", "tibble", "tidyr", "utf8", "vctrs", "viridis", "viridisLite", "waldo", "withr", "zoo"))
data = read.csv("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 3/lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(data)
summary(data)
x = data[,1:4]
y = as.factor(data$Label)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
install.packages("caret")
install.packages("caret")
library(caret)
library(rpart)
install.packages("caret")
library(caret)
library(rpart)
data = read.csv("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 3/lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(data)
summary(data)
x = data[,1:4]
y = as.factor(data$Label)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
plot(model)
text(model)
rpart.plot(model)
#Information Gain
sum(y==predict(model,x,type="class"))/length(y)
#miscalassification error
1-sum(y==predict(model,x,type="class"))/length(y)
model1 = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
plot(model1)
text(model1)
rpart.plot(model1)
#Information Gain
sum(y==predict(model1,x,type="class"))/length(y)
#miscalassification error
1-sum(y==predict(model1,x,type="class"))/length(y)
install.packages("caret")
install.packages("caret")
library(caret)
library(rpart.plot)
data = read.csv("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 3/lenses.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "Label"))
str(data)
summary(data)
x = data[,1:4]
y = as.factor(data$Label)
model = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
plot(model)
text(model)
rpart.plot(model)
#Information Gain
sum(y==predict(model,x,type="class"))/length(y)
#miscalassification error
1-sum(y==predict(model,x,type="class"))/length(y)
model1 = rpart(y~.,x,control=rpart.control(minsplit=0,minbucket=0,cp=-1, maxcompete=0, maxsurrogate=0, usesurrogate=0, xval=0,maxdepth=3))
plot(model1)
text(model1)
rpart.plot(model1)
#Information Gain
sum(y==predict(model1,x,type="class"))/length(y)
#miscalassification error
1-sum(y==predict(model1,x,type="class"))/length(y)
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 4")
liver = read.csv("Liver_data.csv", header = FALSE, col.names = c("mcv", "alkphos", "sgpt", "sgot", "gammagt", "drinks","selector"))
str(liver)
liver$selector <- as.factor(liver$selector)
liver$drinks <- cut(liver$drinks, breaks = c(0, 5,10,15,20),
labels = c('C1', 'C2', "C3", 'C4'), right = FALSE)
liver <- na.omit(liver)
train = subset(liver, liver$selector == 1)
str(train)
test = subset(liver, liver$selector == 2)
str(test)
dim(train)
dim(test)
x_train <- subset(train, select = -c(selector, drinks))
x_test <- subset(test, select = -c(selector, drinks))
library(class)
y_train = train[,6, drop = TRUE]
y_test = test[,6, drop = TRUE]
length(train)
length(test)
fit1 = knn(x_train,x_train,y_train,k=1)
1-sum(y_test==fit1)/length(y_test)
fit2 = knn(x_train,x_train,y_train,k=2)
1-sum(y_test==fit2)/length(y_test)
fit3 = knn(x_train,x_train,y_train,k=3)
1-sum(y_test==fit3)/length(y_test)
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 4")
liver = read.csv("Liver_data.csv", header = FALSE, col.names = c("mcv", "alkphos", "sgpt", "sgot", "gammagt", "drinks","selector"))
str(liver)
liver$selector <- as.factor(liver$selector)
liver$drinks <- cut(liver$drinks, breaks = c(0, 5,10,15,20),
labels = c('C1', 'C2', "C3", 'C4'), right = FALSE)
liver <- na.omit(liver)
train = subset(liver, liver$selector == 1)
str(train)
test = subset(liver, liver$selector == 2)
str(test)
dim(train)
dim(test)
x_train <- subset(train, select = -c(selector, drinks))
x_test <- subset(test, select = -c(selector, drinks))
library(class)
y_train = train[,6, drop = TRUE]
y_test = test[,6, drop = TRUE]
length(train)
length(test)
fit1 = knn(x_train,x_train,y_train,k=1)
1-sum(y_test==fit1)/length(y_test)
fit2 = knn(x_train,x_train,y_train,k=2)
1-sum(y_test==fit2)/length(y_test)
fit3 = knn(x_train,x_train,y_train,k=3)
1-sum(y_test==fit3)/length(y_test)
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 5")
liver = read.csv("Liver_data.csv", header = FALSE, col.names = c("mcv", "alkphos", "sgpt", "sgot", "gammagt", "drinks","selector"))
str(liver)
liver$selector <- as.factor(liver$selector)
liver$drinks <- cut(liver$drinks, breaks = c(0, 5,10,15,20),
labels = c('C1', 'C2', "C3", 'C4'), right = FALSE)
liver <- na.omit(liver)
train = subset(liver, liver$selector == 1)
str(train)
test = subset(liver, liver$selector == 2)
str(test)
dim(train)
dim(test)
x_train <- subset(train, select = -c(selector, drinks))
x_test <- subset(test, select = -c(selector, drinks))
library(class)
y_train = train[,6, drop = TRUE]
y_test = test[,6, drop = TRUE]
length(train)
length(test)
library(e1071)
#SVM
#For training
fit = svm(x_train, y_train)
library(e1071)
install.packages("e1071")
library(e1071)
#SVM
#For training
fit = svm(x_train, y_train)
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 5")
liver = read.csv("Liver_data.csv", header = FALSE, col.names = c("mcv", "alkphos", "sgpt", "sgot", "gammagt", "drinks","selector"))
str(liver)
liver$selector <- as.factor(liver$selector)
liver$drinks <- cut(liver$drinks, breaks = c(0, 5,10,15,20),
labels = c('C1', 'C2', "C3", 'C4'), right = FALSE)
liver <- na.omit(liver)
train = subset(liver, liver$selector == 1)
str(train)
test = subset(liver, liver$selector == 2)
str(test)
dim(train)
dim(test)
x_train <- subset(train, select = -c(selector, drinks))
x_test <- subset(test, select = -c(selector, drinks))
library(class)
y_train = train[,6, drop = TRUE]
y_test = test[,6, drop = TRUE]
length(train)
length(test)
library(e1071)
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 5")
liver = read.csv("Liver_data.csv", header = FALSE, col.names = c("mcv", "alkphos", "sgpt", "sgot", "gammagt", "drinks","selector"))
str(liver)
liver$selector <- as.factor(liver$selector)
liver$drinks <- cut(liver$drinks, breaks = c(0, 5,10,15,20),
labels = c('C1', 'C2', "C3", 'C4'), right = FALSE)
liver <- na.omit(liver)
train = subset(liver, liver$selector == 1)
str(train)
test = subset(liver, liver$selector == 2)
str(test)
dim(train)
dim(test)
x_train <- subset(train, select = -c(selector, drinks))
x_test <- subset(test, select = -c(selector, drinks))
library(class)
y_train = train[,6, drop = TRUE]
y_test = test[,6, drop = TRUE]
length(train)
length(test)
install.packages("e1071")
library(e1071)
install.packages("e1071")
library(e1071)
#SVM
#For training
fit = svm(x_train, y_train)
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 5")
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 5")
liver = read.csv("Liver_data.csv", header = FALSE, col.names = c("mcv", "alkphos", "sgpt", "sgot", "gammagt", "drinks","selector"))
str(liver)
liver$selector <- as.factor(liver$selector)
liver$drinks <- cut(liver$drinks, breaks = c(0, 5,10,15,20),
labels = c('C1', 'C2', "C3", 'C4'), right = FALSE)
liver <- na.omit(liver)
train = subset(liver, liver$selector == 1)
str(train)
test = subset(liver, liver$selector == 2)
str(test)
dim(train)
dim(test)
x_train <- subset(train, select = -c(selector, drinks))
x_test <- subset(test, select = -c(selector, drinks))
library(class)
y_train = train[,6, drop = TRUE]
y_test = test[,6, drop = TRUE]
length(train)
length(test)
#install.packages("e1071")
library(e1071)
#SVM
#For training
fit = svm(x_train, y_train)
1-sum(y_train==predict(fit,x_train))/length(y_train)
#For test data
fit = svm(x_test, y_test)
1-sum(y_test==predict(fit,x_test))/length(y_test)
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 6")
liver=read.csv("Liver_data.csv",header = FALSE,col.names = c("1", "2", "3", "4", "5", "6", "7") )
str(liver)
summary(liver)
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x,4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 6")
liver=read.csv("Liver_data.csv",header = FALSE,col.names = c("1", "2", "3", "4", "5", "6", "7") )
str(liver)
summary(liver)
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 6")
liver=read.csv("Liver_data.csv",header = FALSE,col.names = c("1", "2", "3", "4", "5", "6", "7") )
str(liver)
summary(liver)
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x,4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
#install.packages("factoextra")
data <- read.csv("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 6/Liver_data.csv",header=FALSE)
install.packages("factoextra")
install.packages("factoextra")
data <- read.csv("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 6/Liver_data.csv",header=FALSE)
set.seed(123)
#no of centers = 4
#nstart - how many random sets should be chosen for 4 centers
#iter.max - maximum number of iterations allowed
res.km <- kmeans(scale(data[,-7]), 4, nstart = 25,iter.max=10)
#plotting and assigning points
fviz_cluster(res.km, data = data[, -7],
palette = c("#2E9FDF", "#273746", "#E7B800","#D35400"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/
liver=read.csv("Liver_data.csv",header = FALSE,col.names = c("1", "2", "3", "4", "5", "6", "7") )
str(liver)
summary(liver)
x<-liver[,1:2]
plot(x,pch=19,xlab=expression(x[1]),ylab=expression(x[2]))
fit<-kmeans(x,4)
points(fit$centers,pch=19,col="blue",cex=2)
library(class)
knnfit<-knn(fit$centers,x,as.factor(c(-1,1)))
points(x,col=1+1*as.numeric(knnfit),pch=19)
#install.packages("factoextra")
data <- read.csv("V:/DataScience_2019501043/Data_Mining/Final_exam/Question_4/Liver_data.csv",header=FALSE)
install.packages("factoextra")
data <- read.csv("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 6/Liver_data.csv",header=FALSE)
set.seed(123)
#no of centers = 4
#nstart - how many random sets should be chosen for 4 centers
#iter.max - maximum number of iterations allowed
res.km <- kmeans(scale(data[,-7]), 4, nstart = 25,iter.max=10)
print(res.km)
#plotting and assigning points
fviz_cluster(res.km, data = data[, -7],
palette = c("#2E9FDF", "#273746", "#E7B800","#D35400"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
#plotting and assigning points
library(cluster)
fviz_cluster(res.km, data = data[, -7],
palette = c("#2E9FDF", "#273746", "#E7B800","#D35400"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
library("factoextra")
fviz_cluster(res.km, data = data[, -7],
palette = c("#2E9FDF", "#273746", "#E7B800","#D35400"),
geom = "point",
ellipse.type = "convex",
ggtheme = theme_bw()
)
getwd()
getwd()
setwd("E:/2ndMSIT/Intro_to_ML/DataScience_2019501037/Data_Mining/Late Submission/Solution 7")
data = read.csv("Liver_data.csv", header = FALSE, col.names = c("1", "2", "3", "4", "5", "6", "7"))
str(data)
summary(data)
x = data[,1:5]
y = data[,6]
fit = kmeans(x,4)
library(class)
knnfit = knn(fit$centers,x,as.factor(c(-2,-1,1,2)))
error = 1-sum(knnfit == y)/length(y)
error
