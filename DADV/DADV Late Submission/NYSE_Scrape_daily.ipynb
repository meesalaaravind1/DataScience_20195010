{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seleniumNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading selenium-3.141.0-py2.py3-none-any.whl (904 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\shravya\\anaconda3\\lib\\site-packages (from selenium) (1.26.4)\n",
      "Installing collected packages: selenium\n",
      "\n",
      "Successfully installed selenium-3.141.0\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting webdriver_manager\n",
      "  Downloading webdriver_manager-3.4.2-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\shravya\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.25.1)\n",
      "Collecting configparser\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting crayons\n",
      "  Downloading crayons-0.4.0-py2.py3-none-any.whl (4.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shravya\\anaconda3\\lib\\site-packages (from crayons->webdriver_manager) (0.4.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\shravya\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shravya\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shravya\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\shravya\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.10)\n",
      "Installing collected packages: crayons, configparser, webdriver-manager\n",
      "Successfully installed configparser-5.0.2 crayons-0.4.0 webdriver-manager-3.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import io\n",
    "import gzip\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def scrape_daily(sym):\n",
    "    print(sym)\n",
    "    url = \"https://query1.finance.yahoo.com/v7/finance/download/\"+sym+\"?period1=1451692800&period2=1609545600&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "    response = requests.get(url)\n",
    "    bytes_io = io.BytesIO(response.content)\n",
    "    df_daily = pd.read_csv(bytes_io, error_bad_lines = False)\n",
    "    df_daily.to_csv(sym + \"_daily.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 91.0.4472\n",
      "Get LATEST driver version for 91.0.4472\n",
      "Driver [C:\\Users\\laksh\\.wdm\\drivers\\chromedriver\\win32\\91.0.4472.19\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import io\n",
    "import gzip\n",
    "import time\n",
    "import csv\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from multiprocessing import Pool\n",
    "# import import_ipynb\n",
    "import pandas as pd\n",
    "#from ipynb.fs.full.scrape_daily import scrape_daily\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "driver.get(url)\n",
    "\n",
    "symbols = list()\n",
    "symbols_GICC = dict()\n",
    "\n",
    "table = \"/html/body/div[3]/div[3]/div[5]/div[1]/table[1]\"\n",
    "table = driver.find_element_by_xpath(table)\n",
    "elements = table.find_elements_by_tag_name(\"tr\")[1:]\n",
    "\n",
    "for row in elements:\n",
    "    data = [data.text for data in row.find_elements_by_tag_name(\"td\")]\n",
    "    symbols.append(data[0])\n",
    "    symbols_GICC[data[0]] = data[3]\n",
    "\n",
    "print(len(symbols_GICC))\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Pool(25)\n",
    "    df_daily_list = p.map(scrape_daily, symbols)\n",
    "    p.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
